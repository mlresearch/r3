---
title: On the effectiveness of the skew divergence for statistical language analysis
url: http://www.gatsby.ucl.ac.uk/aistats/aistats2001/files/lee118.pdf
timestamp: Thu, 21 Jan 2021 00:00:00 +0100
biburl: https://dblp.org/rec/conf/aistats/Lee01.bib
abstract: Estimating word co-occurrence probabilities is a problem underlying many
  applications in statistical natural language processing. Distance-weighted (or similarityweighted)
  averaging has been shown to be a promising approach to the analysis of novel co-occurrences.
  Many measures of distributional similarity have been proposed for use in the distance-weighted
  averaging framework; here, we empirically study their stability properties, finding
  that similarity-based estimation appears to make more efficient use of more reliable
  portions of the training data. We also investigate properties of the skew divergence,
  a weighted version of the KullbackLeibler (KL) divergence; our results indicate
  that the skew divergence yields better results than the KL divergence even when
  the KL divergence is applied to more sophisticated probability estimates.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lee01a
month: 0
tex_title: On the effectiveness of the skew divergence for statistical language analysis
firstpage: 176
lastpage: 183
page: 176-183
order: 176
cycles: false
bibtex_editor: Richardson, Thomas S. and Jaakkola, Tommi S.
editor:
- given: Thomas S.
  family: Richardson
- given: Tommi S.
  family: Jaakkola
bibtex_author: Lee, Lillian
author:
- given: Lillian
  family: Lee
date: 2001-01-04
note: Reissued by PMLR on 31 March 2021.
address:
container-title: Proceedings of the Eighth International Workshop on Artificial Intelligence
  and Statistics
volume: R3
genre: inproceedings
issued:
  date-parts:
  - 2001
  - 1
  - 4
pdf: http://proceedings.mlr.press/r3/lee01a/lee01a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
